# SkewBalancer: Automatic Value-Based Skew Fix for Apache Spark

SkewBalancer is a plug-and-play PySpark utility that **automatically detects** value-based skew in numeric columns and **applies smart salting** to balance your dataâ€”no deep Spark knowledge required. ğŸš€

> **For Beginners:** Think of *skewed data* as having too many of the same values in one group, which slows down processing. SkewBalancer spreads those values out evenly.

---

## ğŸš€ Key Features

- **Auto Skew Detection:** Finds the most skewed numeric column using IQR and percentiles.
- **Smart Group Key Selection:** Picks a low-cardinality column (â‰¤â€‰20 uniques) for grouping.
- **Value-Aware Salting:** Splits data into percentile-based â€œzonesâ€ and salts keys.
- **Interactive Visual Reports:**  
  - Z-Score bar charts (before vs. after)  
  - Box plots comparing distributions  
  - Histograms with overlays  
- **Repartition for Performance:** Rebalances partitions on the new salted key.
- **Schema Intelligence:**  
  - `.detectKey()` finds primary/composite keys  
  - `.schemaVisor()` infers optimal Spark types and nullability
- **Logging & Explain Plans:** Saves `.explain()` outputs for side-by-side DAG comparison.
- **One-Click Pipeline:** Chain everything with `.run_full_balance_pipeline()` or `auto_balance_skew()`.

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/yourusername/SkewBalancer.git
cd SkewBalancer
pip install -e .
```

> **Tip:** Installing in â€œeditableâ€ mode lets you tweak the code locally.

---

## ğŸ“˜ Usage Example

```python
from pyspark.sql import SparkSession
from skewbalancer import auto_balance_skew, ValueSkewBalancer

# Start Spark
spark = SparkSession.builder     .appName("SkewBalancerTest")     .master("local[*]")     .getOrCreate()

# Load data (all columns as strings)
df_raw = spark.read.csv("data.csv", header=True)

# Smart schema detection
optimized_schema = ValueSkewBalancer.schemaVisor(df_raw)
df = spark.read.csv("data.csv", header=True, schema=optimized_schema)

# Auto-fix skew
df_balanced = auto_balance_skew(
    df,
    output_dir="outputs",   # where plots/logs go
    partitions=10,          # target number of partitions
    verbose=True
)
```

> **Note for Newcomers:**  
> 1. **Salted Key**: a new column (`salted_key`) that mixes your original value with a small salt number to spread out heavy hitters.  
> 2. **Partitions**: think of these as â€œbucketsâ€ Spark uses; more even buckets = faster jobs.

---

## ğŸ§  How It Works

1. **Detect Skew:** Computes percentiles and IQR to find skewed numeric columns.  
2. **Select Group Key:** Chooses a categorical (string) column with few unique values.  
3. **Apply Salting:** Divides numeric values into zones and appends a salt suffix.  
4. **Visualize & Log:** Generates plots and `.explain()` plans for before/after.  
5. **Repartition:** Rebalances data on the salted key for optimal parallelism.

---

## ğŸ“‚ Project Structure

```
SkewBalancer/
â”œâ”€â”€ outputs/                   # Plots & logs
â”œâ”€â”€ skewbalancer/
â”‚   â”œâ”€â”€ __init__.py            # Exposes public API
â”‚   â””â”€â”€ value_skew_balancer.py # Core logic
â”œâ”€â”€ notebook_test.ipynb        # Step-by-step example
â”œâ”€â”€ README.md                  # (You are here)
â”œâ”€â”€ requirements.txt
â””â”€â”€ setup.py
```

---

## ğŸ”® Future Enhancements

- Auto-plot Spark executor metrics (task times, shuffle stats).  
- Categorical skew detection (beyond numeric).  
- Streaming mode support (micro-batches).  
- Spark UI integration (GraphFrames links).

---

## ğŸ‘¨â€ğŸ’» Author

**Omar Attia** â€“ IBM Data Engineer  
Creator of SkewBalancer and the first **value-based dynamic salting optimizer** for Spark.  
ğŸ”— [GitHub: OmarAttia95](https://github.com/OmarAttia95)

---

## ğŸªª License

[MIT License](LICENSE)
